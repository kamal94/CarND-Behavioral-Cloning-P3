{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import h5py as h5py\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset\n",
    "Before we can use the dataset,  we have to read it from the generated drives. For this purposes, a furnished dataset has been downloaded. UDacity provided this simple dataset, and it can be downloaded from [here](https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def import_dataset(data_source_path, csv_file_name):\n",
    "    images = []\n",
    "    steering_measurements = []\n",
    "    throttle_measurements = []\n",
    "    speed_measurements = []\n",
    "    breaking_measurements = []\n",
    "    with open(data_source_path+\"./\"+csv_file_name) as f:\n",
    "        csv_lines = csv.reader(f)\n",
    "        # skip first line\n",
    "        next(csv_lines)\n",
    "        for line in csv_lines:\n",
    "            center, left, right, steering, throttle, br, speed = line\n",
    "            steering = float(steering)\n",
    "            for img_path, corrected_steering in zip([left, center, right], [steering+0.2, steering, steering-0.2]):\n",
    "                image_path = img_path.strip()\n",
    "                image = cv.imread(image_path)\n",
    "                images.append(image)\n",
    "                steering_measurements.append(corrected_steering)\n",
    "                throttle_measurements.append(throttle)\n",
    "                speed_measurements.append(speed)\n",
    "                breaking_measurements.append(br)\n",
    "\n",
    "    return np.array(images), np.array(steering_measurements), np.array(throttle_measurements), np.array(speed_measurements), np.array(breaking_measurements)\n",
    "\n",
    "images, steering, throttle, speed, breaking = import_dataset('../collected_data', 'driving_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the images\n",
    "Now that we have the images, lets see their shape and see some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sum([1 for image in images if image is None]))\n",
    "print(sum([1 for image in images if image is not None]))\n",
    "print(steering.shape)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_images, x_shape, y_shape, depth = images.shape\n",
    "image_shape = (x_shape, y_shape, depth)\n",
    "print(\"Number of images:\", num_images)\n",
    "print(\"Shape of each image:\", image_shape)\n",
    "print(\"random sample of steering angles:\", random.sample(list(steering), 4))\n",
    "print(\"random sample of breaking:\", random.sample(list(breaking), 4))\n",
    "print(\"random sample of throttle:\", random.sample(list(throttle), 4))\n",
    "print(\"random sample of speed:\", random.sample(list(speed), 4))\n",
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "Now that we have some data, we notice that the track is a closed loop, so the car only trains on turning left. Now, we can flip the images and the steering measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(steering.astype(np.float32)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flipped_images = np.array([np.fliplr(im) for im in images])\n",
    "flipped_measurements = np.array([-1.*m for m in steering])\n",
    "\n",
    "all_images = np.append(images, flipped_images, axis=0)\n",
    "all_steering = np.append(steering, flipped_measurements, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(flipped_images.shape)\n",
    "print(flipped_measurements.shape)\n",
    "print(images.shape)\n",
    "print(all_images.shape)\n",
    "print(steering.shape)\n",
    "print(all_steering.shape)\n",
    "print(steering[0].dtype)\n",
    "print(all_steering[0].dtype)\n",
    "i = random.sample(range(len(steering)), 3)\n",
    "print(steering[i])\n",
    "print(flipped_measurements[i])\n",
    "for ind in i:\n",
    "    plt.figure()\n",
    "    print(steering[ind])\n",
    "    plt.imshow(images[ind])\n",
    "    plt.figure()\n",
    "    print(flipped_measurements[ind])\n",
    "    plt.imshow(flipped_images[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and validation\n",
    "Now that we have the whole dataset, we will save some of it and not train on as part of a validation set. We will save 1/4th of the dataset as validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = all_images\n",
    "# Y = np.column_stack((steering, throttle))\n",
    "Y = all_steering\n",
    "i = random.sample(range(500,700), 3)\n",
    "print(i)\n",
    "print(\"steering[:3]\", steering[i])\n",
    "print(\"throttle[:3]\", throttle[i])\n",
    "print(\"Y[:3]\", Y[i])\n",
    "\n",
    "shuffled_indecies = list(range(len(X)))\n",
    "random.shuffle(shuffled_indecies)\n",
    "print(int(len(shuffled_indecies)*0.33))\n",
    "train_indecies = shuffled_indecies[int(len(shuffled_indecies)*0.33):]\n",
    "test_indecies = shuffled_indecies[:int(len(shuffled_indecies)*0.33)]\n",
    "\n",
    "# check\n",
    "for i in train_indecies:\n",
    "    if i in test_indecies:\n",
    "        print(i,\"is in test indecies\")\n",
    "        break\n",
    "for i in test_indecies:\n",
    "    if i in train_indecies:\n",
    "        print(i,\"is in train indecies\")\n",
    "        break\n",
    "        \n",
    "def save_data(filename, data):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=4)\n",
    "    print(\"done with saving to\", filename)\n",
    "        \n",
    "save_data(\"y_train\", Y[train_indecies])\n",
    "save_data(\"X_train\", X[train_indecies])\n",
    "\n",
    "save_data(\"y_test\", Y[test_indecies])\n",
    "save_data(\"X_test\", X[test_indecies])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint - Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "y_train = load_data(\"y_train\")\n",
    "X_train = load_data(\"X_train\")\n",
    "\n",
    "y_test = load_data(\"y_test\")\n",
    "X_test = load_data(\"X_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the VGG neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is load the pretrained VVG network and its weights. The first time we do this, keras will download the weights, so it may take a while.\n",
    "\n",
    "After the weights are downloaded, we will then cache the output of the newtork for each of our images. If we run all our images through the network, we will have essentially transformed the images to a conceptual matrix that the VVG network was able to translate for us. This conceptual transfer is also the most time demanding part of the neural network, so we will have essentially cached all the training examples for a quick training time on the top layer that we will now create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples_image_filenames, batch_size=32):\n",
    "    num_samples = len(samples_image_filenames)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples_image_filenames)\n",
    "        for offset in range(0, samples_image_filenames, batch_size):\n",
    "            batch_samples = samples_image_filenames[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = './IMG/'+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D, Cropping2D\n",
    "from keras.layers import Input\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.backend import tf as ktf\n",
    "from keras.layers import Lambda\n",
    "import scipy\n",
    "\n",
    "def resize_image(image):\n",
    "    return scipy.misc.imresize(image, (32,32))\n",
    "#     return ktf.image.resize_images(images, (32, 32))\n",
    "\n",
    "def normalize(image):\n",
    "    return image/255.0 - 0.5\n",
    "\n",
    "def train_model():\n",
    "#     with open(\"bottleneck_features_and_labels.p\", 'rb') as f:\n",
    "#         data = pickle.load(f)\n",
    "#         processed_images = data['features']\n",
    "#         processed_steering = data['labels']\n",
    "    \n",
    "#     rescaled_x_train = np.array([resize_image(im) for im in X_train])\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(6, (5,5), activation='relu', input_shape=(32,32,3)))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.add(MaxPooling2D())\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.add(Conv2D(16, (5,5), activation='relu'))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.add(MaxPooling2D())\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.add(Flatten())\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.add(Dense(120))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.add(Dense(80))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.add(Dense(1))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "#     model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "#     datagen = ImageDataGenerator(preprocessing_function=resize_image)\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "#     datagen.fit(X_train)\n",
    "\n",
    "    # fits the model on batches with real-time data augmentation:\n",
    "#     model.fit_generator(\n",
    "#         datagen.flow(X_train, y_train, batch_size=32, shuffle=True),\n",
    "#                        steps_per_epoch=len(X_train) / 32, epochs=50, verbose=2)\n",
    "\n",
    "#     model.fit(rescaled_x_train, y_train)\n",
    "#     model.fit(rescaled_x_train, y_train, epochs=50, batch_size=32, verbose=2, validation_split=0.2, shuffle=True)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(normalize, input_shape=(160, 320, 3)))\n",
    "    model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "    model.add(Conv2D(24, (5,5), strides=(2,2)))\n",
    "    print(model.layers[-1].output_shape)\n",
    "#     model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "    \n",
    "    model.add(Conv2D(36, (5,5), strides=(2,2)))\n",
    "    print(model.layers[-1].output_shape)\n",
    "#     model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(48, (5,5), strides=(2,2)))\n",
    "    print(model.layers[-1].output_shape)\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3)))\n",
    "    print(model.layers[-1].output_shape)\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3,3)))\n",
    "    print(model.layers[-1].output_shape)\n",
    "#     model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "#     print(model.layers[-1].output_shape)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=2, validation_split=0.2, shuffle=True)\n",
    "    model.save(\"model.h5\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"bottleneck_train_features_and_labels.p\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    processed_images = data['features']\n",
    "    processed_steering = data['labels']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(processed_steering.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
